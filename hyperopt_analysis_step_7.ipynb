{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4b2a16-a14e-498a-bea5-585c9d07d27a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Running Hyperopt for pre_covid period ---\n",
      "Initial pre_covid data shape: (128, 42)\n",
      "100%|██████████| 50/50 [00:03<00:00, 16.60trial/s, best loss: 507.0688780837199]\n",
      "Best hyperparameters for pre_covid: {'max_depth': 9.0, 'min_samples_leaf': 3.0, 'min_samples_split': 4.0, 'n_estimators': 50.0}\n",
      "\n",
      "--- Running Hyperopt for covid period ---\n",
      "Initial covid data shape: (22, 42)\n",
      "100%|██████████| 50/50 [00:03<00:00, 13.74trial/s, best loss: 615.7985162953983]\n",
      "Best hyperparameters for covid: {'max_depth': 7.0, 'min_samples_leaf': 3.0, 'min_samples_split': 9.0, 'n_estimators': 160.0}\n",
      "\n",
      "--- Running Hyperopt for post_covid period ---\n",
      "Initial post_covid data shape: (0, 42)\n",
      "No sufficient data for post_covid. Skipping Hyperopt.\n",
      "\n",
      "--- Hyperopt Optimization Results ---\n",
      "pre_covid: {'max_depth': 9.0, 'min_samples_leaf': 3.0, 'min_samples_split': 4.0, 'n_estimators': 50.0}\n",
      "covid: {'max_depth': 7.0, 'min_samples_leaf': 3.0, 'min_samples_split': 9.0, 'n_estimators': 160.0}\n",
      "post_covid: Skipped due to insufficient data\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "import numpy as np\n",
    "\n",
    "def objective(params, X, y):\n",
    "    model = RandomForestRegressor(n_estimators=int(params[\"n_estimators\"]),\n",
    "                                  max_depth=int(params[\"max_depth\"]),\n",
    "                                  min_samples_split=int(params[\"min_samples_split\"]),\n",
    "                                  min_samples_leaf=int(params[\"min_samples_leaf\"]),\n",
    "                                  random_state=42,\n",
    "                                  n_jobs=-1)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    \n",
    "    return {\"loss\": rmse, \"status\": STATUS_OK}\n",
    "\n",
    "space = {\n",
    "    \"n_estimators\": hp.quniform(\"n_estimators\", 50, 200, 10),\n",
    "    \"max_depth\": hp.quniform(\"max_depth\", 5, 20, 1),\n",
    "    \"min_samples_split\": hp.quniform(\"min_samples_split\", 2, 10, 1),\n",
    "    \"min_samples_leaf\": hp.quniform(\"min_samples_leaf\", 1, 5, 1),\n",
    "}\n",
    "\n",
    "combined_df = pd.read_csv(\"data/combined_data_and_features.csv\")\n",
    "pca_df = pd.read_csv(\"data/pca_features.csv\")\n",
    "\n",
    "combined_df[\"date\"] = pd.to_datetime(combined_df[\"date\"])\n",
    "pca_df[\"date\"] = pd.to_datetime(pca_df[\"date\"])\n",
    "\n",
    "\n",
    "\n",
    "merged_data = pd.merge(pca_df, combined_df[[\"company\", \"date\", \"close\"]], on=[\"company\", \"date\"], how=\"inner\")\n",
    "\n",
    "\n",
    "pre_covid_end = pd.to_datetime(\"2019-12-31\")\n",
    "covid_start = pd.to_datetime(\"2020-01-01\")\n",
    "covid_end = pd.to_datetime(\"2021-12-31\")\n",
    "post_covid_start = pd.to_datetime(\"2022-01-01\")\n",
    "\n",
    "\n",
    "\n",
    "periods = {\n",
    "    \"pre_covid\": merged_data[merged_data[\"date\"] <= pre_covid_end],\n",
    "    \"covid\": merged_data[(merged_data[\"date\"] >= covid_start) & (merged_data[\"date\"] <= covid_end)],\n",
    "    \"post_covid\": merged_data[merged_data[\"date\"] >= post_covid_start]\n",
    "}\n",
    "\n",
    "results = {}\n",
    "for period_name, df in periods.items():\n",
    "    print(f\"Initial {period_name} data shape: {df.shape}\")\n",
    "\n",
    "    if df.empty:\n",
    "        print(f\"No sufficient data for {period_name}. Skipping Hyperopt.\")\n",
    "        results[period_name] = \"\"\n",
    "        continue\n",
    "\n",
    "\n",
    "    feature_cols = [col for col in df.columns if \"principal_component\" in col]\n",
    "    X = df[feature_cols]\n",
    "    y = df[\"close\"]\n",
    "\n",
    "\n",
    "    combined_xy = pd.concat([X, y], axis=1).dropna()\n",
    "    X = combined_xy[feature_cols]\n",
    "    y = combined_xy[\"close\"]\n",
    "\n",
    "    if X.empty:\n",
    "        print(f\"No sufficient data for {period_name} after dropping NaNs. Skipping Hyperopt.\")\n",
    "        results[period_name] = \"\"\n",
    "        continue\n",
    "\n",
    "\n",
    "    trials = Trials()\n",
    "    best = fmin(fn=lambda p: objective(p, X, y),\n",
    "                space=space,\n",
    "                algo=tpe.suggest,\n",
    "                max_evals=50,\n",
    "                trials=trials)\n",
    "    \n",
    "    results[period_name] = best\n",
    "    print(f\"Best hyperparameters for {period_name}: {best}\")\n",
    "\n",
    "\n",
    "for period, best_params in results.items():\n",
    "    print(f\"{period}: {best_params}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db19081a-0f19-4ed6-a0ae-4eea25de28ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3] *",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
