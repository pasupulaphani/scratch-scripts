{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e15a0204-b867-4fa6-b2e0-cbcf48643214",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-COVID data shape: (128, 159)\n",
      "COVID data shape: (22, 159)\n",
      "Data split by adjusted time periods and saved to CSV files.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the combined dataset\n",
    "combined_df = pd.read_csv(\"data/combined_data_and_features.csv\")\n",
    "\n",
    "combined_df[\"date\"] = pd.to_datetime(combined_df[\"date\"])\n",
    "\n",
    "pre_covid_end = pd.to_datetime(\"2019-12-31\")\n",
    "covid_start = pd.to_datetime(\"2020-01-01\")\n",
    "covid_end = pd.to_datetime(\"2020-09-17\") # End of available data\n",
    "\n",
    "# Split data into periods\n",
    "pre_covid_df = combined_df[combined_df[\"date\"] <= pre_covid_end]\n",
    "covid_df = combined_df[(combined_df[\"date\"] >= covid_start) & (combined_df[\"date\"] <= covid_end)]\n",
    "\n",
    "# Post-COVID period will be empty with current data, so not creating a separate dataframe for it.\n",
    "\n",
    "# Save the split dataframes to CSV\n",
    "pre_covid_df.to_csv(\"data/pre_covid_features.csv\", index=False)\n",
    "covid_df.to_csv(\"data/covid_features.csv\", index=False)\n",
    "\n",
    "print(f\"Pre-COVID data shape: {pre_covid_df.shape}\")\n",
    "print(f\"COVID data shape: {covid_df.shape}\")\n",
    "print(\"Data split by adjusted time periods and saved to CSV files.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2c3892ef-2379-421f-9b2a-dbd7354fe153",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Performing PCA for pre_covid period ---\n",
      "Number of components to retain 95% variance for pre_covid: 37\n",
      "Cumulative explained variance for pre_covid: 0.9520716743187168\n",
      "PCA analysis complete for pre_covid. PCA features saved to pca_features_pre_covid.csv\n",
      "Explained variance plot saved to explained_variance_pre_covid.png\n",
      "\n",
      "--- Performing PCA for covid period ---\n",
      "Number of components to retain 95% variance for covid: 14\n",
      "Cumulative explained variance for covid: 0.957323171447637\n",
      "PCA analysis complete for covid. PCA features saved to pca_features_covid.csv\n",
      "Explained variance plot saved to explained_variance_covid.png\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def perform_pca_for_period(file_path, period_name):\n",
    "    print(f\"\\n--- Performing PCA for {period_name} period ---\")\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    if df.empty:\n",
    "        print(f\"No data for {period_name} period. Skipping PCA.\")\n",
    "        return\n",
    "\n",
    "    numerical_cols = df.select_dtypes(include=np.number).columns.tolist()\n",
    "    exclude_cols = [col for col in [\"open\", \"high\", \"low\", \"close\", \"adj_close\", \"volume\"] if col in numerical_cols]\n",
    "    features_for_pca = [col for col in numerical_cols if col not in exclude_cols]\n",
    "\n",
    "    X = df[features_for_pca].copy()\n",
    "\n",
    "    # Drop columns that are entirely NaN\n",
    "    X.dropna(axis=1, how='all', inplace=True)\n",
    "\n",
    "    # Impute remaining NaNs with the mean\n",
    "    X = X.fillna(X.mean())\n",
    "\n",
    "    # Drop rows with any remaining NaNs (shouldn't happen if imputation is effective)\n",
    "    X.dropna(inplace=True)\n",
    "\n",
    "    if X.empty:\n",
    "        print(f\"No valid numerical data for {period_name} period after preprocessing. Skipping PCA.\")\n",
    "        return\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    pca = PCA(n_components=0.95)\n",
    "    X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "    print(f\"Number of components to retain 95% variance for {period_name}: {pca.n_components_}\")\n",
    "    print(f\"Cumulative explained variance for {period_name}: {np.sum(pca.explained_variance_ratio_)}\")\n",
    "\n",
    "    pca_df = pd.DataFrame(data=X_pca, columns=[f\"principal_component_{i+1}\" for i in range(pca.n_components_)])\n",
    "    pca_df = pd.concat([df.loc[X.index, [\"company\", \"date\"]], pca_df], axis=1)\n",
    "    pca_df.to_csv(f\"data/pca_features_{period_name}.csv\", index=False)\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "    plt.xlabel(\"Number of Components\")\n",
    "    plt.ylabel(\"Cumulative Explained Variance\")\n",
    "    plt.title(f\"Explained Variance by Number of Components ({period_name})\")\n",
    "    plt.grid(True)\n",
    "    plt.savefig(f\"explained_variance_{period_name}.png\")\n",
    "    plt.close()\n",
    "\n",
    "    print(f\"PCA analysis complete for {period_name}. PCA features saved to pca_features_{period_name}.csv\")\n",
    "    print(f\"Explained variance plot saved to explained_variance_{period_name}.png\")\n",
    "\n",
    "# Perform PCA for each period\n",
    "perform_pca_for_period(\"data/pre_covid_features.csv\", \"pre_covid\")\n",
    "perform_pca_for_period(\"data/covid_features.csv\", \"covid\")\n",
    "# perform_pca_for_period(\"post_covid_features.csv\", \"post_covid\") # This will be empty based on current data\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0e777833-a396-412c-a85c-445b87f38c76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Analyzing Feature Importance for pre_covid period ---\n",
      "\n",
      "--- Top Feature Importances from Random Forest (PCA Components) for pre_covid ---\n",
      "                   Feature  Importance\n",
      "7    principal_component_8    0.247749\n",
      "6    principal_component_7    0.171121\n",
      "0    principal_component_1    0.052269\n",
      "10  principal_component_11    0.052153\n",
      "1    principal_component_2    0.047491\n",
      "4    principal_component_5    0.044097\n",
      "27  principal_component_28    0.041488\n",
      "5    principal_component_6    0.035059\n",
      "17  principal_component_18    0.026956\n",
      "3    principal_component_4    0.026472\n",
      "\n",
      "--- Top contributing original features to the first few Principal Components for pre_covid ---\n",
      "\n",
      "Principal Component 1 (Explained Variance: 0.26):\n",
      "Close                  0.154729\n",
      "Low                    0.154689\n",
      "High                   0.154424\n",
      "Open                   0.154213\n",
      "trend_ichimoku_conv    0.153609\n",
      "momentum_kama          0.153310\n",
      "volatility_kcl         0.153283\n",
      "trend_ichimoku_a       0.153120\n",
      "trend_ema_fast         0.153090\n",
      "volatility_kcc         0.153089\n",
      "dtype: float64\n",
      "\n",
      "Principal Component 2 (Explained Variance: 0.15):\n",
      "trend_vortex_ind_pos     0.178891\n",
      "volatility_dcp           0.174640\n",
      "momentum_rsi             0.173189\n",
      "momentum_stoch_signal    0.171582\n",
      "volatility_bbp           0.170428\n",
      "momentum_stoch           0.169239\n",
      "momentum_wr              0.169239\n",
      "trend_vortex_ind_diff    0.168013\n",
      "trend_adx_neg            0.167528\n",
      "trend_cci                0.165051\n",
      "dtype: float64\n",
      "\n",
      "Principal Component 3 (Explained Variance: 0.07):\n",
      "trend_trix             0.238491\n",
      "others_dr              0.238450\n",
      "return_1d              0.238450\n",
      "others_dlr             0.237461\n",
      "momentum_ppo_signal    0.237001\n",
      "trend_kst              0.235656\n",
      "trend_kst_sig          0.229313\n",
      "momentum_stoch_rsi     0.222407\n",
      "momentum_ppo           0.199177\n",
      "momentum_tsi           0.189431\n",
      "dtype: float64\n",
      "\n",
      "Principal Component 4 (Explained Variance: 0.05):\n",
      "financial_term_freq_growth     0.247300\n",
      "financial_term_freq_revenue    0.247178\n",
      "positive_word_freq             0.236877\n",
      "sentiment_volatility           0.224118\n",
      "avg_sentiment_neu              0.209146\n",
      "Volume                         0.203714\n",
      "volume_vpt                     0.192594\n",
      "financial_term_freq_margin     0.190665\n",
      "readability_flesch             0.187127\n",
      "volume_obv                     0.184987\n",
      "dtype: float64\n",
      "\n",
      "Principal Component 5 (Explained Variance: 0.05):\n",
      "volume_nvi                    0.218654\n",
      "num_questions                 0.204719\n",
      "trend_kst_sig                 0.197747\n",
      "transcript_length             0.190758\n",
      "unemployment                  0.185903\n",
      "ffr                           0.175380\n",
      "forward_looking_statements    0.171828\n",
      "cpi                           0.170929\n",
      "trend_kst                     0.162300\n",
      "trend_trix                    0.162100\n",
      "dtype: float64\n",
      "\n",
      "--- Analyzing Feature Importance for covid period ---\n",
      "\n",
      "--- Top Feature Importances from Random Forest (PCA Components) for covid ---\n",
      "                   Feature  Importance\n",
      "2    principal_component_3    0.385239\n",
      "5    principal_component_6    0.116206\n",
      "0    principal_component_1    0.072944\n",
      "1    principal_component_2    0.064008\n",
      "11  principal_component_12    0.054968\n",
      "6    principal_component_7    0.054595\n",
      "10  principal_component_11    0.052096\n",
      "8    principal_component_9    0.039153\n",
      "9   principal_component_10    0.037300\n",
      "4    principal_component_5    0.036995\n",
      "\n",
      "--- Top contributing original features to the first few Principal Components for covid ---\n",
      "\n",
      "Principal Component 1 (Explained Variance: 0.28):\n",
      "trend_sma_slow         0.153884\n",
      "volatility_bbm         0.153869\n",
      "volatility_dcm         0.153796\n",
      "trend_psar_down        0.153774\n",
      "trend_ema_slow         0.153715\n",
      "momentum_kama          0.153712\n",
      "volatility_kch         0.153632\n",
      "trend_ichimoku_base    0.153631\n",
      "trend_ichimoku_a       0.153629\n",
      "trend_psar_up          0.153626\n",
      "dtype: float64\n",
      "\n",
      "Principal Component 2 (Explained Variance: 0.15):\n",
      "momentum_ppo             0.197285\n",
      "momentum_tsi             0.185862\n",
      "momentum_ppo_signal      0.181614\n",
      "trend_aroon_ind          0.177820\n",
      "trend_trix               0.177153\n",
      "trend_kst                0.174704\n",
      "trend_vortex_ind_diff    0.172509\n",
      "trend_vortex_ind_pos     0.170519\n",
      "trend_aroon_up           0.168478\n",
      "volatility_ui            0.165043\n",
      "dtype: float64\n",
      "\n",
      "Principal Component 3 (Explained Variance: 0.12):\n",
      "volatility_dcw          0.207302\n",
      "volatility_bbw          0.204014\n",
      "volatility_10d          0.187162\n",
      "momentum_stoch_rsi_k    0.182262\n",
      "momentum_stoch_rsi_d    0.181049\n",
      "momentum_ppo_hist       0.177707\n",
      "volatility_5d           0.176857\n",
      "sentiment_shift         0.175601\n",
      "volume_change           0.166150\n",
      "trend_stc               0.165054\n",
      "dtype: float64\n",
      "\n",
      "Principal Component 4 (Explained Variance: 0.07):\n",
      "momentum_pvo                        0.250334\n",
      "momentum_pvo_signal                 0.239960\n",
      "cpi                                 0.227137\n",
      "unemployment                        0.224219\n",
      "financial_term_freq_growth          0.219835\n",
      "trend_mass_index                    0.213123\n",
      "positive_word_freq                  0.197113\n",
      "trend_adx                           0.175163\n",
      "avg_question_sentiment              0.171090\n",
      "sentiment_by_section_opening_neg    0.166051\n",
      "dtype: float64\n",
      "\n",
      "Principal Component 5 (Explained Variance: 0.07):\n",
      "others_dr             0.197766\n",
      "return_1d             0.197766\n",
      "others_dlr            0.197437\n",
      "avg_sentiment_neu     0.177810\n",
      "momentum_uo           0.174117\n",
      "avg_sentiment_pos     0.173340\n",
      "momentum_stoch_rsi    0.171899\n",
      "positive_word_freq    0.171488\n",
      "volatility_kcp        0.169148\n",
      "transcript_length     0.164041\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "\n",
    "def analyze_feature_importance_for_period(pca_file_path, combined_file_path, period_name):\n",
    "    print(f\"\\n--- Analyzing Feature Importance for {period_name} period ---\")\n",
    "    pca_df = pd.read_csv(pca_file_path)\n",
    "    combined_df = pd.read_csv(combined_file_path)\n",
    "\n",
    "    if pca_df.empty or combined_df.empty:\n",
    "        print(f\"No data for {period_name} period. Skipping feature importance analysis.\")\n",
    "        return\n",
    "\n",
    "    # Ensure date columns are datetime objects for merging\n",
    "    pca_df[\"date\"] = pd.to_datetime(pca_df[\"date\"])\n",
    "    combined_df[\"date\"] = pd.to_datetime(combined_df[\"date\"])\n",
    "\n",
    "    # Merge PCA features with the target variable (e.g., 'close' price from combined_df)\n",
    "    merged_data = pd.merge(pca_df, combined_df[[\"company\", \"date\", \"close\"]], on=[\"company\", \"date\"], how=\"inner\")\n",
    "\n",
    "    # Define features (X) and target (y)\n",
    "    X = merged_data.drop(columns=[\"company\", \"date\", \"close\"])\n",
    "    y = merged_data[\"close\"]\n",
    "\n",
    "    # Handle any remaining NaNs in X\n",
    "    X = X.fillna(X.mean())\n",
    "\n",
    "    # Split data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Train the Random Forest Regressor\n",
    "    rf_model = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "    rf_model.fit(X_train, y_train)\n",
    "\n",
    "    # Get feature importances\n",
    "    feature_importances = rf_model.feature_importances_\n",
    "\n",
    "    # Create a DataFrame for feature importances\n",
    "    features_df = pd.DataFrame({\n",
    "        'Feature': X.columns,\n",
    "        'Importance': feature_importances\n",
    "    })\n",
    "\n",
    "    # Sort by importance\n",
    "    features_df = features_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "    print(f\"\\n--- Top Feature Importances from Random Forest (PCA Components) for {period_name} ---\")\n",
    "    print(features_df.head(10)) # Print top 10 PCA component importances\n",
    "\n",
    "    # To understand the original factors, we need to analyze the PCA components themselves.\n",
    "    # Re-create X_original and PCA object for this period\n",
    "    numerical_cols = combined_df.select_dtypes(include=np.number).columns.tolist()\n",
    "    exclude_cols = [col for col in [\"open\", \"high\", \"low\", \"close\", \"adj_close\", \"volume\"] if col in numerical_cols]\n",
    "    features_for_pca = [col for col in numerical_cols if col not in exclude_cols]\n",
    "\n",
    "    X_original = combined_df[features_for_pca].copy()\n",
    "    X_original.dropna(axis=1, how=\"all\", inplace=True)\n",
    "    X_original = X_original.fillna(X_original.mean())\n",
    "    X_original.dropna(inplace=True) # Drop rows with any remaining NaNs\n",
    "\n",
    "    if X_original.empty:\n",
    "        print(f\"No valid original numerical data for {period_name} period after preprocessing. Cannot analyze original feature contributions.\")\n",
    "        return\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled_original = scaler.fit_transform(X_original)\n",
    "\n",
    "    pca = PCA(n_components=0.95)\n",
    "    pca.fit(X_scaled_original)\n",
    "\n",
    "    print(f\"\\n--- Top contributing original features to the first few Principal Components for {period_name} ---\")\n",
    "    num_components_to_show = min(5, pca.n_components_)\n",
    "    for i in range(num_components_to_show):\n",
    "        component = pca.components_[i]\n",
    "        loadings = pd.Series(component, index=X_original.columns)\n",
    "        sorted_loadings = loadings.abs().sort_values(ascending=False)\n",
    "        print(f\"\\nPrincipal Component {i+1} (Explained Variance: {pca.explained_variance_ratio_[i]:.2f}):\")\n",
    "        print(sorted_loadings.head(10)) # Show top 10 contributing features\n",
    "\n",
    "# Analyze for each period\n",
    "analyze_feature_importance_for_period(\"data/pca_features_pre_covid.csv\", \"data/pre_covid_features.csv\", \"pre_covid\")\n",
    "analyze_feature_importance_for_period(\"data/pca_features_covid.csv\", \"data/covid_features.csv\", \"covid\")\n",
    "# analyze_feature_importance_for_period(\"pca_features_post_covid.csv\", \"post_covid_features.csv\", \"post_covid\") # Not available with current data\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8df6d83-69ee-4c58-bf93-60fb805e4534",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3] *",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
